12/05/2024 14:13:24 - INFO - __main__ -   device: cuda n_gpu: 3, distributed training: False, 16-bits training: False
12/05/2024 14:13:25 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/lei/.cache/torch/pytorch_transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1
12/05/2024 14:13:25 - INFO - pytorch_transformers.modeling_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/lei/.cache/torch/pytorch_transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391
12/05/2024 14:13:25 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "ner",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 12,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

12/05/2024 14:13:26 - INFO - pytorch_transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/lei/.cache/torch/pytorch_transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2
12/05/2024 14:13:29 - INFO - pytorch_transformers.modeling_utils -   Weights of Ner not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
12/05/2024 14:13:29 - INFO - pytorch_transformers.modeling_utils -   Weights from pretrained model not used in Ner: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
12/05/2024 14:13:39 - INFO - pytorch_transformers.modeling_utils -   loading configuration file out_base/config.json
12/05/2024 14:13:39 - INFO - pytorch_transformers.modeling_utils -   Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "ner",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 12,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 28996
}

12/05/2024 14:13:39 - INFO - pytorch_transformers.modeling_utils -   loading weights file out_base/pytorch_model.bin
12/05/2024 14:13:41 - INFO - pytorch_transformers.tokenization_utils -   Model name 'out_base' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc). Assuming 'out_base' is a path or url to a directory containing tokenizer files.
12/05/2024 14:13:41 - INFO - pytorch_transformers.tokenization_utils -   loading file out_base/vocab.txt
12/05/2024 14:13:41 - INFO - pytorch_transformers.tokenization_utils -   loading file out_base/added_tokens.json
12/05/2024 14:13:41 - INFO - pytorch_transformers.tokenization_utils -   loading file out_base/special_tokens_map.json
12/05/2024 14:13:41 - INFO - pytorch_transformers.tokenization_utils -   loading file out_base/tokenizer_config.json
12/05/2024 14:13:42 - INFO - __main__ -   *** Example ***
12/05/2024 14:13:42 - INFO - __main__ -   guid: dev-0
12/05/2024 14:13:42 - INFO - __main__ -   tokens: CR ##IC ##KE ##T - L ##EI ##CE ##ST ##ER ##S ##H ##IR ##E T ##A ##KE O ##VE ##R AT TO ##P A ##FT ##ER IN ##NI ##NG ##S VI ##CT ##OR ##Y .
12/05/2024 14:13:42 - INFO - __main__ -   input_ids: 101 15531 9741 22441 1942 118 149 27514 10954 9272 9637 1708 3048 18172 2036 157 1592 22441 152 17145 2069 13020 16972 2101 138 26321 9637 15969 27451 11780 1708 7118 16647 9565 3663 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   *** Example ***
12/05/2024 14:13:42 - INFO - __main__ -   guid: dev-1
12/05/2024 14:13:42 - INFO - __main__ -   tokens: L ##ON ##D ##ON 1996 - 08 - 30
12/05/2024 14:13:42 - INFO - __main__ -   input_ids: 101 149 11414 2137 11414 1820 118 4775 118 1476 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   *** Example ***
12/05/2024 14:13:42 - INFO - __main__ -   guid: dev-2
12/05/2024 14:13:42 - INFO - __main__ -   tokens: West Indian all - round ##er Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .
12/05/2024 14:13:42 - INFO - __main__ -   input_ids: 101 1537 1890 1155 118 1668 1200 5676 14068 1261 1300 1111 3383 1113 5286 1112 21854 3222 8860 1118 1126 6687 1105 3614 2326 1107 1160 1552 1106 1321 1166 1120 1103 1246 1104 1103 2514 2899 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   *** Example ***
12/05/2024 14:13:42 - INFO - __main__ -   guid: dev-3
12/05/2024 14:13:42 - INFO - __main__ -   tokens: Their stay on top , though , may be short - lived as title rivals Essex , Derbyshire and Surrey all closed in on victory while Kent made up for lost time in their rain - affected match against Nottinghamshire .
12/05/2024 14:13:42 - INFO - __main__ -   input_ids: 101 2397 2215 1113 1499 117 1463 117 1336 1129 1603 118 2077 1112 1641 9521 8493 117 15964 1105 9757 1155 1804 1107 1113 2681 1229 5327 1189 1146 1111 1575 1159 1107 1147 4458 118 4634 1801 1222 21942 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   *** Example ***
12/05/2024 14:13:42 - INFO - __main__ -   guid: dev-4
12/05/2024 14:13:42 - INFO - __main__ -   tokens: After bowling Somerset out for 83 on the opening morning at Grace Road , Leicestershire extended their first innings by 94 runs before being bowled out for 29 ##6 with England disc ##ard Andy C ##ad ##dick taking three for 83 .
12/05/2024 14:13:42 - INFO - __main__ -   input_ids: 101 1258 11518 8860 1149 1111 6032 1113 1103 2280 2106 1120 4378 1914 117 21854 2925 1147 1148 6687 1118 5706 2326 1196 1217 21663 1149 1111 1853 1545 1114 1652 6187 2881 4827 140 3556 25699 1781 1210 1111 6032 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:42 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
12/05/2024 14:13:44 - INFO - __main__ -   ***** Running evaluation *****
12/05/2024 14:13:44 - INFO - __main__ -     Num examples = 3250
12/05/2024 14:13:44 - INFO - __main__ -     Batch size = 8
Evaluating:   0%|          | 0/407 [00:00<?, ?it/s]Evaluating:   0%|          | 1/407 [00:00<02:51,  2.37it/s]Evaluating:   1%|          | 3/407 [00:00<02:06,  3.20it/s]Evaluating:   1%|          | 5/407 [00:00<01:34,  4.25it/s]Evaluating:   2%|▏         | 7/407 [00:00<01:12,  5.55it/s]Evaluating:   2%|▏         | 9/407 [00:00<00:56,  7.07it/s]Evaluating:   3%|▎         | 12/407 [00:00<00:44,  8.80it/s]Evaluating:   4%|▎         | 15/407 [00:01<00:36, 10.62it/s]Evaluating:   4%|▍         | 18/407 [00:01<00:31, 12.41it/s]Evaluating:   5%|▌         | 21/407 [00:01<00:27, 14.04it/s]Evaluating:   6%|▌         | 24/407 [00:01<00:24, 15.54it/s]Evaluating:   7%|▋         | 27/407 [00:01<00:22, 16.76it/s]Evaluating:   7%|▋         | 30/407 [00:01<00:21, 17.75it/s]Evaluating:   8%|▊         | 33/407 [00:02<00:20, 18.56it/s]Evaluating:   9%|▉         | 36/407 [00:02<00:19, 19.09it/s]Evaluating:  10%|▉         | 39/407 [00:02<00:18, 19.47it/s]Evaluating:  10%|█         | 42/407 [00:02<00:18, 19.75it/s]Evaluating:  11%|█         | 45/407 [00:02<00:18, 19.94it/s]Evaluating:  12%|█▏        | 48/407 [00:02<00:17, 20.08it/s]Evaluating:  13%|█▎        | 51/407 [00:02<00:17, 20.06it/s]Evaluating:  13%|█▎        | 54/407 [00:03<00:17, 20.19it/s]Evaluating:  14%|█▍        | 57/407 [00:03<00:17, 20.27it/s]Evaluating:  15%|█▍        | 60/407 [00:03<00:17, 20.33it/s]Evaluating:  15%|█▌        | 63/407 [00:03<00:16, 20.29it/s]Evaluating:  16%|█▌        | 66/407 [00:03<00:16, 20.33it/s]Evaluating:  17%|█▋        | 69/407 [00:03<00:16, 20.38it/s]Evaluating:  18%|█▊        | 72/407 [00:03<00:16, 20.40it/s]Evaluating:  18%|█▊        | 75/407 [00:04<00:16, 20.43it/s]Evaluating:  19%|█▉        | 78/407 [00:04<00:16, 20.45it/s]Evaluating:  20%|█▉        | 81/407 [00:04<00:15, 20.47it/s]Evaluating:  21%|██        | 84/407 [00:04<00:15, 20.46it/s]Evaluating:  21%|██▏       | 87/407 [00:04<00:15, 20.45it/s]Evaluating:  22%|██▏       | 90/407 [00:04<00:15, 20.45it/s]Evaluating:  23%|██▎       | 93/407 [00:04<00:15, 20.28it/s]Evaluating:  24%|██▎       | 96/407 [00:05<00:15, 20.31it/s]Evaluating:  24%|██▍       | 99/407 [00:05<00:15, 20.35it/s]Evaluating:  25%|██▌       | 102/407 [00:05<00:14, 20.37it/s]Evaluating:  26%|██▌       | 105/407 [00:05<00:14, 20.38it/s]Evaluating:  27%|██▋       | 108/407 [00:05<00:14, 20.37it/s]Evaluating:  27%|██▋       | 111/407 [00:05<00:14, 20.37it/s]Evaluating:  28%|██▊       | 114/407 [00:05<00:14, 20.37it/s]Evaluating:  29%|██▊       | 117/407 [00:06<00:14, 20.40it/s]Evaluating:  29%|██▉       | 120/407 [00:06<00:14, 20.39it/s]Evaluating:  30%|███       | 123/407 [00:06<00:13, 20.39it/s]Evaluating:  31%|███       | 126/407 [00:06<00:13, 20.38it/s]Evaluating:  32%|███▏      | 129/407 [00:06<00:13, 20.39it/s]Evaluating:  32%|███▏      | 132/407 [00:06<00:13, 20.38it/s]Evaluating:  33%|███▎      | 135/407 [00:07<00:13, 20.38it/s]Evaluating:  34%|███▍      | 138/407 [00:07<00:13, 20.35it/s]Evaluating:  35%|███▍      | 141/407 [00:07<00:13, 20.37it/s]Evaluating:  35%|███▌      | 144/407 [00:07<00:12, 20.37it/s]Evaluating:  36%|███▌      | 147/407 [00:07<00:12, 20.36it/s]Evaluating:  37%|███▋      | 150/407 [00:07<00:12, 20.34it/s]Evaluating:  38%|███▊      | 153/407 [00:07<00:12, 20.35it/s]Evaluating:  38%|███▊      | 156/407 [00:08<00:12, 20.34it/s]Evaluating:  39%|███▉      | 159/407 [00:08<00:12, 20.32it/s]Evaluating:  40%|███▉      | 162/407 [00:08<00:12, 20.34it/s]Evaluating:  41%|████      | 165/407 [00:08<00:11, 20.37it/s]Evaluating:  41%|████▏     | 168/407 [00:08<00:11, 20.35it/s]Evaluating:  42%|████▏     | 171/407 [00:08<00:11, 20.34it/s]Evaluating:  43%|████▎     | 174/407 [00:08<00:11, 20.36it/s]Evaluating:  43%|████▎     | 177/407 [00:09<00:11, 20.37it/s]Evaluating:  44%|████▍     | 180/407 [00:09<00:11, 20.38it/s]Evaluating:  45%|████▍     | 183/407 [00:09<00:10, 20.39it/s]Evaluating:  46%|████▌     | 186/407 [00:09<00:10, 20.38it/s]Evaluating:  46%|████▋     | 189/407 [00:09<00:10, 20.37it/s]Evaluating:  47%|████▋     | 192/407 [00:09<00:10, 20.38it/s]Evaluating:  48%|████▊     | 195/407 [00:09<00:10, 20.36it/s]Evaluating:  49%|████▊     | 198/407 [00:10<00:10, 20.34it/s]Evaluating:  49%|████▉     | 201/407 [00:10<00:10, 20.36it/s]Evaluating:  50%|█████     | 204/407 [00:10<00:09, 20.37it/s]Evaluating:  51%|█████     | 207/407 [00:10<00:09, 20.36it/s]Evaluating:  52%|█████▏    | 210/407 [00:10<00:09, 20.42it/s]Evaluating:  52%|█████▏    | 213/407 [00:10<00:09, 20.42it/s]Evaluating:  53%|█████▎    | 216/407 [00:10<00:09, 20.43it/s]Evaluating:  54%|█████▍    | 219/407 [00:11<00:09, 20.28it/s]Evaluating:  55%|█████▍    | 222/407 [00:11<00:09, 20.34it/s]Evaluating:  55%|█████▌    | 225/407 [00:11<00:08, 20.33it/s]Evaluating:  56%|█████▌    | 228/407 [00:11<00:08, 20.34it/s]Evaluating:  57%|█████▋    | 231/407 [00:11<00:08, 20.36it/s]Evaluating:  57%|█████▋    | 234/407 [00:11<00:08, 20.26it/s]Evaluating:  58%|█████▊    | 237/407 [00:12<00:08, 20.30it/s]Evaluating:  59%|█████▉    | 240/407 [00:12<00:08, 20.30it/s]Evaluating:  60%|█████▉    | 243/407 [00:12<00:08, 20.28it/s]Evaluating:  60%|██████    | 246/407 [00:12<00:07, 20.29it/s]Evaluating:  61%|██████    | 249/407 [00:12<00:07, 20.30it/s]Evaluating:  62%|██████▏   | 252/407 [00:12<00:07, 20.27it/s]Evaluating:  63%|██████▎   | 255/407 [00:12<00:07, 20.26it/s]Evaluating:  63%|██████▎   | 258/407 [00:13<00:07, 20.26it/s]Evaluating:  64%|██████▍   | 261/407 [00:13<00:07, 20.29it/s]Evaluating:  65%|██████▍   | 264/407 [00:13<00:07, 20.28it/s]Evaluating:  66%|██████▌   | 267/407 [00:13<00:06, 20.28it/s]Evaluating:  66%|██████▋   | 270/407 [00:13<00:06, 20.37it/s]Evaluating:  67%|██████▋   | 273/407 [00:13<00:06, 20.39it/s]Evaluating:  68%|██████▊   | 276/407 [00:13<00:06, 20.42it/s]Evaluating:  69%|██████▊   | 279/407 [00:14<00:06, 20.38it/s]Evaluating:  69%|██████▉   | 282/407 [00:14<00:06, 20.38it/s]Evaluating:  70%|███████   | 285/407 [00:14<00:05, 20.39it/s]Evaluating:  71%|███████   | 288/407 [00:14<00:05, 20.45it/s]Evaluating:  71%|███████▏  | 291/407 [00:14<00:05, 20.39it/s]Evaluating:  72%|███████▏  | 294/407 [00:14<00:05, 20.41it/s]Evaluating:  73%|███████▎  | 297/407 [00:14<00:05, 20.31it/s]Evaluating:  74%|███████▎  | 300/407 [00:15<00:05, 20.28it/s]Evaluating:  74%|███████▍  | 303/407 [00:15<00:05, 20.29it/s]Evaluating:  75%|███████▌  | 306/407 [00:15<00:04, 20.33it/s]Evaluating:  76%|███████▌  | 309/407 [00:15<00:04, 20.35it/s]Evaluating:  77%|███████▋  | 312/407 [00:15<00:04, 20.31it/s]Evaluating:  77%|███████▋  | 315/407 [00:15<00:04, 20.29it/s]Evaluating:  78%|███████▊  | 318/407 [00:16<00:04, 20.31it/s]Evaluating:  79%|███████▉  | 321/407 [00:16<00:04, 20.30it/s]Evaluating:  80%|███████▉  | 324/407 [00:16<00:04, 20.35it/s]Evaluating:  80%|████████  | 327/407 [00:16<00:03, 20.38it/s]Evaluating:  81%|████████  | 330/407 [00:16<00:03, 20.37it/s]Evaluating:  82%|████████▏ | 333/407 [00:16<00:03, 20.39it/s]Evaluating:  83%|████████▎ | 336/407 [00:16<00:03, 20.39it/s]Evaluating:  83%|████████▎ | 339/407 [00:17<00:03, 20.36it/s]Evaluating:  84%|████████▍ | 342/407 [00:17<00:03, 20.31it/s]Evaluating:  85%|████████▍ | 345/407 [00:17<00:03, 20.26it/s]Evaluating:  86%|████████▌ | 348/407 [00:17<00:02, 20.27it/s]Evaluating:  86%|████████▌ | 351/407 [00:17<00:02, 20.23it/s]Evaluating:  87%|████████▋ | 354/407 [00:17<00:02, 20.27it/s]Evaluating:  88%|████████▊ | 357/407 [00:17<00:02, 20.30it/s]Evaluating:  88%|████████▊ | 360/407 [00:18<00:02, 20.30it/s]Evaluating:  89%|████████▉ | 363/407 [00:18<00:02, 20.29it/s]Evaluating:  90%|████████▉ | 366/407 [00:18<00:02, 20.29it/s]Evaluating:  91%|█████████ | 369/407 [00:18<00:01, 20.27it/s]Evaluating:  91%|█████████▏| 372/407 [00:18<00:01, 20.23it/s]Evaluating:  92%|█████████▏| 375/407 [00:18<00:01, 20.25it/s]Evaluating:  93%|█████████▎| 378/407 [00:18<00:01, 20.26it/s]Evaluating:  94%|█████████▎| 381/407 [00:19<00:01, 20.23it/s]Evaluating:  94%|█████████▍| 384/407 [00:19<00:01, 20.24it/s]Evaluating:  95%|█████████▌| 387/407 [00:19<00:00, 20.24it/s]Evaluating:  96%|█████████▌| 390/407 [00:19<00:00, 20.24it/s]Evaluating:  97%|█████████▋| 393/407 [00:19<00:00, 20.23it/s]Evaluating:  97%|█████████▋| 396/407 [00:19<00:00, 20.25it/s]Evaluating:  98%|█████████▊| 399/407 [00:20<00:00, 20.25it/s]Evaluating:  99%|█████████▉| 402/407 [00:20<00:00, 20.17it/s]Evaluating: 100%|█████████▉| 405/407 [00:20<00:00, 20.17it/s]Evaluating: 100%|██████████| 407/407 [00:20<00:00, 19.98it/s]
12/05/2024 14:14:04 - INFO - __main__ -   
             precision    recall  f1-score   support

        LOC     0.9520    0.9505    0.9512      1837
        ORG     0.9050    0.9165    0.9107      1341
       MISC     0.8394    0.8731    0.8559       922
        PER     0.9655    0.9712    0.9683      1842

avg / total     0.9281    0.9372    0.9326      5942

12/05/2024 14:14:04 - INFO - __main__ -   ***** Eval results *****
12/05/2024 14:14:04 - INFO - __main__ -   
             precision    recall  f1-score   support

        LOC     0.9520    0.9505    0.9512      1837
        ORG     0.9050    0.9165    0.9107      1341
       MISC     0.8394    0.8731    0.8559       922
        PER     0.9655    0.9712    0.9683      1842

avg / total     0.9281    0.9372    0.9326      5942

