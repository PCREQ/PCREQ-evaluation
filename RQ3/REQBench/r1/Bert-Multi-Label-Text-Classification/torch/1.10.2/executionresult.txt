Traceback (most recent call last):
  File "run_bert.py", line 10, in <module>
    from pybert.io.bert_processor import BertProcessor
  File "/home/lei/compatibility_analysis/pytorch/1.0/Bert-Multi-Label-Text-Classification/pybert/io/bert_processor.py", line 8, in <module>
    from transformers import BertTokenizer
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/__init__.py", line 135, in <module>
    from .pipelines import (
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/pipelines.py", line 38, in <module>
    from .tokenization_auto import AutoTokenizer
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/tokenization_auto.py", line 119, in <module>
    from .tokenization_albert_fast import AlbertTokenizerFast
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/tokenization_albert_fast.py", line 23, in <module>
    from .tokenization_utils_fast import PreTrainedTokenizerFast
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py", line 30, in <module>
    from .convert_slow_tokenizer import convert_slow_tokenizer
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py", line 28, in <module>
    from transformers.utils import sentencepiece_model_pb2 as model
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/transformers/utils/sentencepiece_model_pb2.py", line 38, in <module>
    _descriptor.EnumValueDescriptor(name="UNIGRAM", index=0, number=1, options=None, type=None),
  File "/home/lei/anaconda3/envs/py37-6/lib/python3.7/site-packages/google/protobuf/descriptor.py", line 796, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot not be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
