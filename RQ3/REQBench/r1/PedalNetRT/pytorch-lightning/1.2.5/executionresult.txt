GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]

  | Name    | Type    | Params
------------------------------------
0 | wavenet | WaveNet | 10.6 K
------------------------------------
10.6 K    Trainable params
0         Non-trainable params
10.6 K    Total params
0.042     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  4.73it/s]                                                                      /home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule
  warnings.warn(*args, **kwargs)
/home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.
# log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/24 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s] Epoch 0:   4%|▍         | 1/24 [00:00<00:05,  4.50it/s]Epoch 0:   4%|▍         | 1/24 [00:00<00:05,  4.49it/s, loss=2.99, v_num=558]Epoch 0:   8%|▊         | 2/24 [00:00<00:02,  7.52it/s, loss=2.43, v_num=558]Epoch 0:  12%|█▎        | 3/24 [00:00<00:02,  9.73it/s, loss=28.7, v_num=558]Epoch 0:  17%|█▋        | 4/24 [00:00<00:01, 11.36it/s, loss=28.7, v_num=558]Epoch 0:  17%|█▋        | 4/24 [00:00<00:01, 11.35it/s, loss=21.7, v_num=558]Epoch 0:  21%|██        | 5/24 [00:00<00:01, 12.73it/s, loss=17.7, v_num=558]Epoch 0:  25%|██▌       | 6/24 [00:00<00:01, 13.93it/s, loss=45.2, v_num=558]Epoch 0:  29%|██▉       | 7/24 [00:00<00:01, 14.95it/s, loss=45.2, v_num=558]Epoch 0:  29%|██▉       | 7/24 [00:00<00:01, 14.94it/s, loss=102, v_num=558] Epoch 0:  33%|███▎      | 8/24 [00:00<00:01, 15.80it/s, loss=91.4, v_num=558]Epoch 0:  38%|███▊      | 9/24 [00:00<00:00, 16.52it/s, loss=82.6, v_num=558]Epoch 0:  42%|████▏     | 10/24 [00:00<00:00, 17.17it/s, loss=82.6, v_num=558]Epoch 0:  42%|████▏     | 10/24 [00:00<00:00, 17.16it/s, loss=75.3, v_num=558]Epoch 0:  46%|████▌     | 11/24 [00:00<00:00, 17.70it/s, loss=79.5, v_num=558]Epoch 0:  50%|█████     | 12/24 [00:00<00:00, 18.21it/s, loss=86.1, v_num=558]Epoch 0:  54%|█████▍    | 13/24 [00:00<00:00, 18.65it/s, loss=86.1, v_num=558]Epoch 0:  54%|█████▍    | 13/24 [00:00<00:00, 18.64it/s, loss=79.8, v_num=558]Epoch 0:  58%|█████▊    | 14/24 [00:00<00:00, 19.04it/s, loss=83.7, v_num=558]Epoch 0:  62%|██████▎   | 15/24 [00:00<00:00, 19.38it/s, loss=83, v_num=558]  Epoch 0:  67%|██████▋   | 16/24 [00:00<00:00, 19.72it/s, loss=83, v_num=558]Epoch 0:  67%|██████▋   | 16/24 [00:00<00:00, 19.71it/s, loss=77.9, v_num=558]Epoch 0:  71%|███████   | 17/24 [00:00<00:00, 20.00it/s, loss=73.4, v_num=558]Epoch 0:  75%|███████▌  | 18/24 [00:00<00:00, 18.57it/s, loss=69.3, v_num=558]Epoch 0:  79%|███████▉  | 19/24 [00:00<00:00, 19.51it/s, loss=69.3, v_num=558]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/6 [00:00<?, ?it/s][A
Validating:  17%|█▋        | 1/6 [00:00<00:01,  3.64it/s][AEpoch 0:  92%|█████████▏| 22/24 [00:01<00:00, 17.37it/s, loss=69.3, v_num=558]Epoch 0: 100%|██████████| 24/24 [00:01<00:00, 17.57it/s, loss=69.3, v_num=558]
                                                         [AEpoch 0: 100%|██████████| 24/24 [00:01<00:00, 17.33it/s, loss=69.3, v_num=558]
