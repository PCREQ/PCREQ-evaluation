GPU available: True, used: True
TPU available: None, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]

  | Name    | Type    | Params
------------------------------------
0 | wavenet | WaveNet | 10.6 K
------------------------------------
10.6 K    Trainable params
0         Non-trainable params
10.6 K    Total params
0.042     Total estimated model params size (MB)
Validation sanity check: 0it [00:00, ?it/s]Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]Validation sanity check:  50%|█████     | 1/2 [00:00<00:00,  4.89it/s]                                                                      /home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The validation_epoch_end should not return anything as of 9.1. To log, use self.log(...) or self.write(...) directly in the LightningModule
  warnings.warn(*args, **kwargs)
/home/lei/anaconda3/envs/py37-5/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:52: UserWarning: The {log:dict keyword} was deprecated in 0.9.1 and will be removed in 1.0.0
Please use self.log(...) inside the lightningModule instead.
# log on a step or aggregate epoch metric to the logger and/or progress bar (inside LightningModule)
self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)
  warnings.warn(*args, **kwargs)
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/24 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/24 [00:00<?, ?it/s] Epoch 0:   4%|▍         | 1/24 [00:00<00:05,  4.20it/s]Epoch 0:   4%|▍         | 1/24 [00:00<00:05,  4.19it/s, loss=0.834, v_num=511]Epoch 0:   8%|▊         | 2/24 [00:00<00:03,  7.08it/s, loss=1.06, v_num=511] Epoch 0:  12%|█▎        | 3/24 [00:00<00:02,  9.27it/s, loss=1.77, v_num=511]Epoch 0:  17%|█▋        | 4/24 [00:00<00:01, 10.92it/s, loss=1.77, v_num=511]Epoch 0:  17%|█▋        | 4/24 [00:00<00:01, 10.91it/s, loss=1.49, v_num=511]Epoch 0:  21%|██        | 5/24 [00:00<00:01, 12.19it/s, loss=2.65, v_num=511]Epoch 0:  25%|██▌       | 6/24 [00:00<00:01, 13.30it/s, loss=4.82, v_num=511]Epoch 0:  29%|██▉       | 7/24 [00:00<00:01, 14.28it/s, loss=4.82, v_num=511]Epoch 0:  29%|██▉       | 7/24 [00:00<00:01, 14.27it/s, loss=5.7, v_num=511] Epoch 0:  33%|███▎      | 8/24 [00:00<00:01, 15.14it/s, loss=5.05, v_num=511]Epoch 0:  38%|███▊      | 9/24 [00:00<00:00, 15.87it/s, loss=4.68, v_num=511]Epoch 0:  42%|████▏     | 10/24 [00:00<00:00, 16.53it/s, loss=4.68, v_num=511]Epoch 0:  42%|████▏     | 10/24 [00:00<00:00, 16.52it/s, loss=4.28, v_num=511]Epoch 0:  46%|████▌     | 11/24 [00:00<00:00, 17.08it/s, loss=4.16, v_num=511]Epoch 0:  50%|█████     | 12/24 [00:00<00:00, 17.59it/s, loss=3.86, v_num=511]Epoch 0:  54%|█████▍    | 13/24 [00:00<00:00, 18.04it/s, loss=3.86, v_num=511]Epoch 0:  54%|█████▍    | 13/24 [00:00<00:00, 18.04it/s, loss=3.73, v_num=511]Epoch 0:  58%|█████▊    | 14/24 [00:00<00:00, 18.46it/s, loss=3.52, v_num=511]Epoch 0:  62%|██████▎   | 15/24 [00:00<00:00, 18.82it/s, loss=3.41, v_num=511]Epoch 0:  67%|██████▋   | 16/24 [00:00<00:00, 19.16it/s, loss=3.41, v_num=511]Epoch 0:  67%|██████▋   | 16/24 [00:00<00:00, 19.15it/s, loss=3.33, v_num=511]Epoch 0:  71%|███████   | 17/24 [00:00<00:00, 19.46it/s, loss=3.17, v_num=511]Epoch 0:  75%|███████▌  | 18/24 [00:01<00:00, 17.76it/s, loss=3.02, v_num=511]Epoch 0:  79%|███████▉  | 19/24 [00:01<00:00, 18.65it/s, loss=3.02, v_num=511]
Validating: 0it [00:00, ?it/s][A
Validating:   0%|          | 0/6 [00:00<?, ?it/s][A
Validating:  17%|█▋        | 1/6 [00:00<00:01,  2.87it/s][AEpoch 0:  92%|█████████▏| 22/24 [00:01<00:00, 15.87it/s, loss=3.02, v_num=511]Epoch 0: 100%|██████████| 24/24 [00:01<00:00, 15.87it/s, loss=3.02, v_num=511]
                                                         [AEpoch 0: 100%|██████████| 24/24 [00:01<00:00, 15.69it/s, loss=3.02, v_num=511]
